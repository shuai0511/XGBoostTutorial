{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is part of the [Machine Learning class](https://github.com/erachelson/MLclass) by [Emmanuel Rachelson](https://personnel.isae-supaero.fr/emmanuel-rachelson?lang=en) and was written by Erwan Lecarpentier and Jonathan Sprauel.\n",
    "\n",
    "License: CC-BY-SA-NC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:22pt; line-height:25pt; font-weight:bold; text-align:center;\">XGBoost<br>Introduction to XGBoost</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "[XGBoost](https://xgboost.readthedocs.io/en/latest/) is a library. It implements machine learning algorithms (Figure 1) that are all working with the [gradient boosting](https://en.wikipedia.org/wiki/Gradient_boosting) framework. It can be used for regression and classification. It produces efficient models to deal with standard tabular data as opposed to more fancy data structures like images, sounds, videos etc.\n",
    "\n",
    "<img id=\"fig1\" src=\"img/machine_learning.png\">\n",
    "<center>Figure 1: a machine learning algorithm</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Practice Course is composed of 3 parts - each part is meant to be done in about 1 hour :\n",
    "* In the **first notebook**, you will learn the **basic of XGBoost**, how to apply it on a dataset and tune it to obtain the best performances.\n",
    "* In the **second notebook**, we will focus on **ensemble methods** and explain what makes XGBoost different from other models.\n",
    "* Finally in the **last notebook** you will see how the choice of a method (such as XGBoost) is a key element of a tradeoff between **Bias and Variance**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <a id=\"sec1\"></a> What is XGBoost?\n",
    "\n",
    "XGBoost (eXtreme Gradient Boosting) is a library for Gradient Tree Boosting in C++, Java, Python, R and Julia, that was initially developped by Tianqi Chen.\n",
    "XGBoost has recently been dominating applied machine learning and Kaggle competitions for structured or tabular data. For reference (and inspiration), you can have a look at this curated list of first, second and third place competition [winners that used XGBoost](https://github.com/dmlc/xgboost/tree/master/demo#machine-learning-challenge-winning-solutions).\n",
    "\n",
    "> When in doubt, use xgboost.\n",
    "> [Avito Winner’s Interview](http://blog.kaggle.com/2015/08/26/avito-winners-interview-1st-place-owen-zhang/)\n",
    "\n",
    "\n",
    "XGBoost has been designed for speed and performance : it is usually faster than sklearn's GradientBoost, even though they are fundamentally the same as they are both gradient boosting implementations.\n",
    "\n",
    "## Installing XGBoost\n",
    "\n",
    "With Anaconda use :\n",
    "```conda install -c anaconda py-xgboost=0.60```\n",
    "\n",
    "With pip use :\n",
    "```pip install xgboost```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install xgboost -U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple XGBoost usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin, be sure that you have the following dependencies and run the import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /home/codespace/.local/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.12/site-packages (2.1.1)\n",
      "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.12/site-packages (2.2.3)\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[15 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "  \u001b[31m   \u001b[0m rather than 'sklearn' for pip commands.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Here is how to fix this error in the main use cases:\n",
      "  \u001b[31m   \u001b[0m - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "  \u001b[31m   \u001b[0m - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "  \u001b[31m   \u001b[0m   (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "  \u001b[31m   \u001b[0m - if the 'sklearn' package is used by one of your dependencies,\n",
      "  \u001b[31m   \u001b[0m   it would be great if you take some time to track which package uses\n",
      "  \u001b[31m   \u001b[0m   'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "  \u001b[31m   \u001b[0m - as a last resort, set the environment variable\n",
      "  \u001b[31m   \u001b[0m   SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m More information is available at\n",
      "  \u001b[31m   \u001b[0m https://github.com/scikit-learn/sklearn-pypi-package\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install seaborn numpy pandas sklearn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\software\\anaconda\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGboost natively uses a specific format, that is optimized in term of memory and computation speed : DMatrix.\n",
    "When using numpy, you have to convert it explicitely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The major parameters are as following - we will focus on the parameters later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = {\n",
    "    'max_depth': 3,  # the maximum depth of each tree\n",
    "    'eta': 0.3,  # Learning rate, the training step for each iteration\n",
    "    'silent': 1,  # logging mode - quieter and faster\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': 3}  # the number of classes that exist in this dataset\n",
    "num_round = 20  # the number of training iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we run the training and prediction with an api that is similar to sklearn - though we have to the true prediction : for each line, we must select the class where the probability is the highest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 44.1 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "preds = bst.predict(dtest)\n",
    "predictions = np.asarray([np.argmax(line) for line in preds])\n",
    "#print (precision_score(y_test, predictions, average='macro')) # 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a bit less performance, you can also directly use the pandas-compatible functions that mirror exactly the sklearn api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 45.4 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "mod = XGBClassifier(**param)\n",
    "mod.fit(X_train, y_train)\n",
    "predictions = mod.predict(X_test)\n",
    "#print (precision_score(y_test, predictions, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can save the model either with pickle or with the dedicated function :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bst = xgb.train(param, dtrain, num_round)\n",
    "preds = bst.predict(dtest)\n",
    "\n",
    "bst.save_model('xgb.model')\n",
    "\n",
    "bst2 = xgb.Booster(model_file='xgb.model')\n",
    "\n",
    "preds2 = bst2.predict(dtest)\n",
    "# assert they are the same\n",
    "assert np.sum(np.abs(preds2 - preds)) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A complete exemple : Classification of stars, Galaxies, Quasars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this first application of XGBoost, we will try to classify observations of space to be either stars, galaxies or quasars.\n",
    "We are using data from the [Sloan Digital Sky Survey](http://www.sdss.org/)\n",
    "\n",
    "### About the SDSS\n",
    "The Sloan Digital Sky Survey is a project which offers public data of space observations. Observations have been made since 1998 and have been made accessible to everyone who is interested.\n",
    "\n",
    "For this purpose a special 2.5 m diameter telescope was built at the Apache Point Observatory in New Mexico, USA. The telescope uses a camera of 30 CCD-Chips with 2048x2048 image points each. The chips are ordered in 5 rows with 6 chips in each row. Each row observes the space through different optical filters (u, g, r, i, z) at wavelengths of approximately 354, 476, 628, 769, 925 nm.\n",
    "\n",
    "The telescope covers around one quarter of the earth's sky - therefore focuses on the northern part of the sky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objid</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>run</th>\n",
       "      <th>rerun</th>\n",
       "      <th>camcol</th>\n",
       "      <th>field</th>\n",
       "      <th>specobjid</th>\n",
       "      <th>class</th>\n",
       "      <th>redshift</th>\n",
       "      <th>plate</th>\n",
       "      <th>mjd</th>\n",
       "      <th>fiberid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1237648704577142822</td>\n",
       "      <td>183.531326</td>\n",
       "      <td>0.089693</td>\n",
       "      <td>19.47406</td>\n",
       "      <td>17.04240</td>\n",
       "      <td>15.94699</td>\n",
       "      <td>15.50342</td>\n",
       "      <td>15.22531</td>\n",
       "      <td>752</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>267</td>\n",
       "      <td>3722360139651588096</td>\n",
       "      <td>STAR</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>3306</td>\n",
       "      <td>54922</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1237648704577142859</td>\n",
       "      <td>183.598371</td>\n",
       "      <td>0.135285</td>\n",
       "      <td>18.66280</td>\n",
       "      <td>17.21449</td>\n",
       "      <td>16.67637</td>\n",
       "      <td>16.48922</td>\n",
       "      <td>16.39150</td>\n",
       "      <td>752</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>267</td>\n",
       "      <td>363814405953054720</td>\n",
       "      <td>STAR</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>323</td>\n",
       "      <td>51615</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1237648704577208477</td>\n",
       "      <td>183.680207</td>\n",
       "      <td>0.126185</td>\n",
       "      <td>19.38298</td>\n",
       "      <td>18.19169</td>\n",
       "      <td>17.47428</td>\n",
       "      <td>17.08732</td>\n",
       "      <td>16.80125</td>\n",
       "      <td>752</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>268</td>\n",
       "      <td>323274319570429952</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.123111</td>\n",
       "      <td>287</td>\n",
       "      <td>52023</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1237648704577273907</td>\n",
       "      <td>183.870529</td>\n",
       "      <td>0.049911</td>\n",
       "      <td>17.76536</td>\n",
       "      <td>16.60272</td>\n",
       "      <td>16.16116</td>\n",
       "      <td>15.98233</td>\n",
       "      <td>15.90438</td>\n",
       "      <td>752</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>269</td>\n",
       "      <td>3722365362331820032</td>\n",
       "      <td>STAR</td>\n",
       "      <td>-0.000111</td>\n",
       "      <td>3306</td>\n",
       "      <td>54922</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1237648704577273909</td>\n",
       "      <td>183.883288</td>\n",
       "      <td>0.102557</td>\n",
       "      <td>17.55025</td>\n",
       "      <td>16.26342</td>\n",
       "      <td>16.43869</td>\n",
       "      <td>16.55492</td>\n",
       "      <td>16.61326</td>\n",
       "      <td>752</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>269</td>\n",
       "      <td>3722365912087633920</td>\n",
       "      <td>STAR</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>3306</td>\n",
       "      <td>54922</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 objid          ra       dec         u         g         r  \\\n",
       "0  1237648704577142822  183.531326  0.089693  19.47406  17.04240  15.94699   \n",
       "1  1237648704577142859  183.598371  0.135285  18.66280  17.21449  16.67637   \n",
       "2  1237648704577208477  183.680207  0.126185  19.38298  18.19169  17.47428   \n",
       "3  1237648704577273907  183.870529  0.049911  17.76536  16.60272  16.16116   \n",
       "4  1237648704577273909  183.883288  0.102557  17.55025  16.26342  16.43869   \n",
       "\n",
       "          i         z  run  rerun  camcol  field            specobjid   class  \\\n",
       "0  15.50342  15.22531  752    301       4    267  3722360139651588096    STAR   \n",
       "1  16.48922  16.39150  752    301       4    267   363814405953054720    STAR   \n",
       "2  17.08732  16.80125  752    301       4    268   323274319570429952  GALAXY   \n",
       "3  15.98233  15.90438  752    301       4    269  3722365362331820032    STAR   \n",
       "4  16.55492  16.61326  752    301       4    269  3722365912087633920    STAR   \n",
       "\n",
       "   redshift  plate    mjd  fiberid  \n",
       "0 -0.000009   3306  54922      491  \n",
       "1 -0.000055    323  51615      541  \n",
       "2  0.123111    287  52023      513  \n",
       "3 -0.000111   3306  54922      510  \n",
       "4  0.000590   3306  54922      512  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdss_df = pd.read_csv('Skyserver_SQL2_27_2018 6_51_39 PM.csv', skiprows=1)\n",
    "sdss_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objid</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>run</th>\n",
       "      <th>rerun</th>\n",
       "      <th>camcol</th>\n",
       "      <th>field</th>\n",
       "      <th>specobjid</th>\n",
       "      <th>redshift</th>\n",
       "      <th>plate</th>\n",
       "      <th>mjd</th>\n",
       "      <th>fiberid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.237650e+18</td>\n",
       "      <td>175.529987</td>\n",
       "      <td>14.836148</td>\n",
       "      <td>18.619355</td>\n",
       "      <td>17.371931</td>\n",
       "      <td>16.840963</td>\n",
       "      <td>16.583579</td>\n",
       "      <td>16.422833</td>\n",
       "      <td>981.034800</td>\n",
       "      <td>301.0</td>\n",
       "      <td>3.648700</td>\n",
       "      <td>302.380100</td>\n",
       "      <td>1.645022e+18</td>\n",
       "      <td>0.143726</td>\n",
       "      <td>1460.986400</td>\n",
       "      <td>52943.533300</td>\n",
       "      <td>353.069400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.173967e+12</td>\n",
       "      <td>47.783439</td>\n",
       "      <td>25.212207</td>\n",
       "      <td>0.828656</td>\n",
       "      <td>0.945457</td>\n",
       "      <td>1.067764</td>\n",
       "      <td>1.141805</td>\n",
       "      <td>1.203188</td>\n",
       "      <td>273.305024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.666183</td>\n",
       "      <td>162.577763</td>\n",
       "      <td>2.013998e+18</td>\n",
       "      <td>0.388774</td>\n",
       "      <td>1788.778371</td>\n",
       "      <td>1511.150651</td>\n",
       "      <td>206.298149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.237647e+18</td>\n",
       "      <td>8.235100</td>\n",
       "      <td>-5.382632</td>\n",
       "      <td>12.988970</td>\n",
       "      <td>12.799550</td>\n",
       "      <td>12.431600</td>\n",
       "      <td>11.947210</td>\n",
       "      <td>11.610410</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>301.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2.995782e+17</td>\n",
       "      <td>-0.004136</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>51578.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.237649e+18</td>\n",
       "      <td>157.370946</td>\n",
       "      <td>-0.539035</td>\n",
       "      <td>18.178035</td>\n",
       "      <td>16.815100</td>\n",
       "      <td>16.173333</td>\n",
       "      <td>15.853705</td>\n",
       "      <td>15.618285</td>\n",
       "      <td>752.000000</td>\n",
       "      <td>301.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>3.389250e+17</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>51900.000000</td>\n",
       "      <td>186.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.237649e+18</td>\n",
       "      <td>180.394514</td>\n",
       "      <td>0.404166</td>\n",
       "      <td>18.853095</td>\n",
       "      <td>17.495135</td>\n",
       "      <td>16.858770</td>\n",
       "      <td>16.554985</td>\n",
       "      <td>16.389945</td>\n",
       "      <td>756.000000</td>\n",
       "      <td>301.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>4.966580e+17</td>\n",
       "      <td>0.042591</td>\n",
       "      <td>441.000000</td>\n",
       "      <td>51997.000000</td>\n",
       "      <td>351.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.237651e+18</td>\n",
       "      <td>201.547279</td>\n",
       "      <td>35.649397</td>\n",
       "      <td>19.259232</td>\n",
       "      <td>18.010145</td>\n",
       "      <td>17.512675</td>\n",
       "      <td>17.258550</td>\n",
       "      <td>17.141447</td>\n",
       "      <td>1331.000000</td>\n",
       "      <td>301.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>414.000000</td>\n",
       "      <td>2.881300e+18</td>\n",
       "      <td>0.092579</td>\n",
       "      <td>2559.000000</td>\n",
       "      <td>54468.000000</td>\n",
       "      <td>510.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.237652e+18</td>\n",
       "      <td>260.884382</td>\n",
       "      <td>68.542265</td>\n",
       "      <td>19.599900</td>\n",
       "      <td>19.918970</td>\n",
       "      <td>24.802040</td>\n",
       "      <td>28.179630</td>\n",
       "      <td>22.833060</td>\n",
       "      <td>1412.000000</td>\n",
       "      <td>301.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>9.468834e+18</td>\n",
       "      <td>5.353854</td>\n",
       "      <td>8410.000000</td>\n",
       "      <td>57481.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              objid            ra           dec             u             g  \\\n",
       "count  1.000000e+04  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean   1.237650e+18    175.529987     14.836148     18.619355     17.371931   \n",
       "std    1.173967e+12     47.783439     25.212207      0.828656      0.945457   \n",
       "min    1.237647e+18      8.235100     -5.382632     12.988970     12.799550   \n",
       "25%    1.237649e+18    157.370946     -0.539035     18.178035     16.815100   \n",
       "50%    1.237649e+18    180.394514      0.404166     18.853095     17.495135   \n",
       "75%    1.237651e+18    201.547279     35.649397     19.259232     18.010145   \n",
       "max    1.237652e+18    260.884382     68.542265     19.599900     19.918970   \n",
       "\n",
       "                  r             i             z           run    rerun  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.0   \n",
       "mean      16.840963     16.583579     16.422833    981.034800    301.0   \n",
       "std        1.067764      1.141805      1.203188    273.305024      0.0   \n",
       "min       12.431600     11.947210     11.610410    308.000000    301.0   \n",
       "25%       16.173333     15.853705     15.618285    752.000000    301.0   \n",
       "50%       16.858770     16.554985     16.389945    756.000000    301.0   \n",
       "75%       17.512675     17.258550     17.141447   1331.000000    301.0   \n",
       "max       24.802040     28.179630     22.833060   1412.000000    301.0   \n",
       "\n",
       "             camcol         field     specobjid      redshift         plate  \\\n",
       "count  10000.000000  10000.000000  1.000000e+04  10000.000000  10000.000000   \n",
       "mean       3.648700    302.380100  1.645022e+18      0.143726   1460.986400   \n",
       "std        1.666183    162.577763  2.013998e+18      0.388774   1788.778371   \n",
       "min        1.000000     11.000000  2.995782e+17     -0.004136    266.000000   \n",
       "25%        2.000000    184.000000  3.389250e+17      0.000081    301.000000   \n",
       "50%        4.000000    299.000000  4.966580e+17      0.042591    441.000000   \n",
       "75%        5.000000    414.000000  2.881300e+18      0.092579   2559.000000   \n",
       "max        6.000000    768.000000  9.468834e+18      5.353854   8410.000000   \n",
       "\n",
       "                mjd       fiberid  \n",
       "count  10000.000000  10000.000000  \n",
       "mean   52943.533300    353.069400  \n",
       "std     1511.150651    206.298149  \n",
       "min    51578.000000      1.000000  \n",
       "25%    51900.000000    186.750000  \n",
       "50%    51997.000000    351.000000  \n",
       "75%    54468.000000    510.000000  \n",
       "max    57481.000000   1000.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdss_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous cells, we only checked a few classical elements when facing a dataset : \n",
    "* There is no missing data, that we should complete\n",
    "* Most features remain within reasonable values, for each columns\n",
    "\n",
    "The goal is to classify each data into either the Galaxy, Star or QSO class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GALAXY    4998\n",
       "STAR      4152\n",
       "QSO        850\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdss_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "Before applying any classification algorithm, let's look a bit more and transform the data : first we remove the column that obviously won't help classify into the correct class, such as the objects id and parameters of the camera at the moment of observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>class</th>\n",
       "      <th>redshift</th>\n",
       "      <th>plate</th>\n",
       "      <th>mjd</th>\n",
       "      <th>fiberid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183.531326</td>\n",
       "      <td>0.089693</td>\n",
       "      <td>19.47406</td>\n",
       "      <td>17.0424</td>\n",
       "      <td>15.94699</td>\n",
       "      <td>15.50342</td>\n",
       "      <td>15.22531</td>\n",
       "      <td>STAR</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>3306</td>\n",
       "      <td>54922</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ra       dec         u        g         r         i         z  \\\n",
       "0  183.531326  0.089693  19.47406  17.0424  15.94699  15.50342  15.22531   \n",
       "\n",
       "  class  redshift  plate    mjd  fiberid  \n",
       "0  STAR -0.000009   3306  54922      491  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdss_df.drop(['objid', 'run', 'rerun', 'camcol', 'field', 'specobjid'], axis=1, inplace=True)\n",
    "sdss_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we look at a few interesting features (univariate analysis) : by plotting the distribution of each class along this feature, we can estimate if this feature can help in classifying the data.\n",
    "\n",
    "For instance, we can see that redshift seems to have good correlation, while ascension and declination does not differ significantly between the 3 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcd7bda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3,figsize=(16, 4))\n",
    "ax = sns.distplot(sdss_df[sdss_df['class']=='STAR'].redshift, bins = 30, ax = axes[0], kde = False)\n",
    "ax.set_title('Star')\n",
    "ax = sns.distplot(sdss_df[sdss_df['class']=='GALAXY'].redshift, bins = 30, ax = axes[1], kde = False)\n",
    "ax.set_title('Galaxy')\n",
    "ax = sns.distplot(sdss_df[sdss_df['class']=='QSO'].redshift, bins = 30, ax = axes[2], kde = False)\n",
    "ax = ax.set_title('QSO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241m.\u001b[39mlmplot(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mra\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdec\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39msdss_df, hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m, fit_reg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, palette\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoolwarm\u001b[39m\u001b[38;5;124m'\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, aspect\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEquatorial coordinates\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "sns.lmplot(x='ra', y='dec', data=sdss_df, hue='class', fit_reg=False, palette='coolwarm', size=6, aspect=2)\n",
    "plt.title('Equatorial coordinates')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we transform a few features : we transform the different bands through a PCA, we encode the classes and scale the extreme values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>class</th>\n",
       "      <th>redshift</th>\n",
       "      <th>plate</th>\n",
       "      <th>mjd</th>\n",
       "      <th>fiberid</th>\n",
       "      <th>PCA_1</th>\n",
       "      <th>PCA_2</th>\n",
       "      <th>PCA_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>183.531326</td>\n",
       "      <td>0.089693</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>3306</td>\n",
       "      <td>54922</td>\n",
       "      <td>491</td>\n",
       "      <td>-1.507202</td>\n",
       "      <td>-1.377293</td>\n",
       "      <td>-0.265119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>183.598371</td>\n",
       "      <td>0.135285</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>323</td>\n",
       "      <td>51615</td>\n",
       "      <td>541</td>\n",
       "      <td>-0.195758</td>\n",
       "      <td>-0.028410</td>\n",
       "      <td>-0.155695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>183.680207</td>\n",
       "      <td>0.126185</td>\n",
       "      <td>0</td>\n",
       "      <td>0.123111</td>\n",
       "      <td>287</td>\n",
       "      <td>52023</td>\n",
       "      <td>513</td>\n",
       "      <td>1.297604</td>\n",
       "      <td>-0.590023</td>\n",
       "      <td>0.140338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>183.870529</td>\n",
       "      <td>0.049911</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.000111</td>\n",
       "      <td>3306</td>\n",
       "      <td>54922</td>\n",
       "      <td>510</td>\n",
       "      <td>-1.446117</td>\n",
       "      <td>0.566685</td>\n",
       "      <td>-0.009272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>183.883288</td>\n",
       "      <td>0.102557</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>3306</td>\n",
       "      <td>54922</td>\n",
       "      <td>512</td>\n",
       "      <td>-0.849271</td>\n",
       "      <td>1.287505</td>\n",
       "      <td>-0.397689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ra       dec  class  redshift  plate    mjd  fiberid     PCA_1  \\\n",
       "0  183.531326  0.089693      2 -0.000009   3306  54922      491 -1.507202   \n",
       "1  183.598371  0.135285      2 -0.000055    323  51615      541 -0.195758   \n",
       "2  183.680207  0.126185      0  0.123111    287  52023      513  1.297604   \n",
       "3  183.870529  0.049911      2 -0.000111   3306  54922      510 -1.446117   \n",
       "4  183.883288  0.102557      2  0.000590   3306  54922      512 -0.849271   \n",
       "\n",
       "      PCA_2     PCA_3  \n",
       "0 -1.377293 -0.265119  \n",
       "1 -0.028410 -0.155695  \n",
       "2 -0.590023  0.140338  \n",
       "3  0.566685 -0.009272  \n",
       "4  1.287505 -0.397689  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdss_df_fe = sdss_df\n",
    "\n",
    "# encode class labels to integers\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(sdss_df_fe['class'])\n",
    "sdss_df_fe['class'] = y_encoded\n",
    "\n",
    "# Principal Component Analysis\n",
    "pca = PCA(n_components=3)\n",
    "ugriz = pca.fit_transform(sdss_df_fe[['u', 'g', 'r', 'i', 'z']])\n",
    "\n",
    "# update dataframe \n",
    "sdss_df_fe = pd.concat((sdss_df_fe, pd.DataFrame(ugriz)), axis=1)\n",
    "sdss_df_fe.rename_axis({0: 'PCA_1', 1: 'PCA_2', 2: 'PCA_3'}, axis=1, inplace = True)\n",
    "sdss_df_fe.drop(['u', 'g', 'r', 'i', 'z'], axis=1, inplace=True)\n",
    "sdss_df_fe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "sdss = scaler.fit_transform(sdss_df_fe.drop('class', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "Using XGboost is similar in many ways with the sklearn api : we define a model and call the *fit* function on the training data; the *predict* function makes the prediction.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>Exercice 1 :</b> Complete the following functions.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(..., test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost's prediction accuracy is: 99.36\n",
      "Wall time: 1.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgbC = XGBClassifier(n_estimators=100)\n",
    "xgbC.fit(...)\n",
    "preds = xgbC.predict(...)\n",
    "acc_xgb = (preds == y_test).sum().astype(float) / len(preds)*100\n",
    "print(\"XGBoost's prediction accuracy is: %3.2f\" % (acc_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "...\n",
    "acc_rfc = (preds == y_test).sum().astype(float) / len(preds)*100\n",
    "print(\"Scikit-Learn's Random Forest Classifier's prediction accuracy is: %3.2f\" % (acc_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "svc = SVC()\n",
    "...\n",
    "acc_svc = (preds == y_test).sum().astype(float) / len(preds)*100\n",
    "print(\"Scikit-Learn's Support Vector Machine Classifier's prediction accuracy is: %3.2f\" % (acc_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can focus a bit more on the performance comparison between XGBoost and Random Forest, in term of optimality :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Scores:', array([ 0.9985119 ,  0.98958333,  0.99104478,  0.99552239,  0.98059701,\n",
      "        0.9880597 ,  0.98953662,  0.98953662,  0.99252616,  0.9955157 ]))\n",
      "('Mean:', 0.99104342158521952)\n",
      "('Standard Deviation:', 0.0047195536718038673)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rfc_cv = RandomForestClassifier(n_estimators=100)\n",
    "scores = cross_val_score(rfc_cv, X_train, y_train, cv=10, scoring = \"accuracy\")\n",
    "print(\"Scores:\", scores)\n",
    "print(\"Mean:\", scores.mean())\n",
    "print(\"Standard Deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Scores:', array([ 0.99404762,  0.99255952,  0.99552239,  0.99701493,  0.98955224,\n",
      "        0.99104478,  0.99252616,  0.98953662,  0.99252616,  0.9955157 ]))\n",
      "('Mean:', 0.99298461049971165)\n",
      "('Standard Deviation:', 0.0024135853667884553)\n"
     ]
    }
   ],
   "source": [
    "xgb_cv = XGBClassifier(n_estimators=100)\n",
    "scores = cross_val_score(xgb_cv, X_train, y_train, cv=10, scoring = \"accuracy\")\n",
    "print(\"Scores:\", scores)\n",
    "print(\"Mean:\", scores.mean())\n",
    "print(\"Standard Deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, XGBoost also allows to obtain the feature importance list :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>redshift</th>\n",
       "      <td>0.894122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA_3</th>\n",
       "      <td>0.032230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA_2</th>\n",
       "      <td>0.017915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA_1</th>\n",
       "      <td>0.013244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dec</th>\n",
       "      <td>0.010970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fiberid</th>\n",
       "      <td>0.009574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mjd</th>\n",
       "      <td>0.007393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plate</th>\n",
       "      <td>0.007389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ra</th>\n",
       "      <td>0.007164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Importance\n",
       "Feature             \n",
       "redshift    0.894122\n",
       "PCA_3       0.032230\n",
       "PCA_2       0.017915\n",
       "PCA_1       0.013244\n",
       "dec         0.010970\n",
       "fiberid     0.009574\n",
       "mjd         0.007393\n",
       "plate       0.007389\n",
       "ra          0.007164"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = pd.DataFrame({\n",
    "    'Feature': sdss_df_fe.drop('class', axis=1).columns,\n",
    "    'Importance': xgbC.feature_importances_\n",
    "})\n",
    "importances = importances.sort_values(by='Importance', ascending=False)\n",
    "importances = importances.set_index('Feature')\n",
    "importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A focus on the parameters\n",
    "\n",
    "XGBoost has <[many parameters](https://xgboost.readthedocs.io/en/latest/parameter.html); we will explain them a bit by following this guideline, that woks well on most problems :\n",
    "\n",
    "* Choose a relatively high learning rate (**learning_rate**)\n",
    "* Determine the optimum number of trees for this learning rate. (**n_estimators**)\n",
    "* Tune tree-specific parameters ( **max_depth, min_child_weight, gamma, subsample, colsample_bytree** for instance) for the decided learning rate and number of trees.\n",
    "* Tune regularization parameters (**lambda, alpha**)\n",
    "\n",
    "For most of the functions, instead of relying on sklearn cross_valisation function we will use XGBoost function called \"cv\" which performs cross-validation at each boosting iteration and returns the optimum number of trees required.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>Exercice 2 :</b> Complete the following functions.\n",
    "</div>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.989946304686\n"
     ]
    }
   ],
   "source": [
    "num_round = 100\n",
    "param = {\n",
    "    \"learning_rate\" :0.3,\n",
    "    \"n_estimators\":1000,\n",
    "    'silent': 1,\n",
    "    'objective': 'multi:softprob',\n",
    "    'num_class': 3\n",
    "}\n",
    "\n",
    "...\n",
    "\n",
    "cvresult = xgb.cv(param, dtrain, nfold=10, num_boost_round=param['n_estimators'],  early_stopping_rounds=50)\n",
    "\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "preds = bst.predict(dtest)\n",
    "predictions = np.asarray([np.argmax(line) for line in preds])\n",
    "print (precision_score(y_test, predictions, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 4)\n"
     ]
    }
   ],
   "source": [
    "print(cvresult.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>Exercice 3 :</b> Complete the following code to tune the tree parameters : max_depth and min_child_weight\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.99299, std: 0.00241, params: {'max_depth': 3, 'min_child_weight': 1},\n",
       "  mean: 0.99299, std: 0.00284, params: {'max_depth': 3, 'min_child_weight': 3},\n",
       "  mean: 0.99224, std: 0.00346, params: {'max_depth': 3, 'min_child_weight': 5},\n",
       "  mean: 0.99313, std: 0.00269, params: {'max_depth': 5, 'min_child_weight': 1},\n",
       "  mean: 0.99299, std: 0.00366, params: {'max_depth': 5, 'min_child_weight': 3},\n",
       "  mean: 0.99239, std: 0.00362, params: {'max_depth': 5, 'min_child_weight': 5},\n",
       "  mean: 0.99284, std: 0.00266, params: {'max_depth': 7, 'min_child_weight': 1},\n",
       "  mean: 0.99299, std: 0.00334, params: {'max_depth': 7, 'min_child_weight': 3},\n",
       "  mean: 0.99269, std: 0.00380, params: {'max_depth': 7, 'min_child_weight': 5},\n",
       "  mean: 0.99284, std: 0.00266, params: {'max_depth': 9, 'min_child_weight': 1},\n",
       "  mean: 0.99299, std: 0.00334, params: {'max_depth': 9, 'min_child_weight': 3},\n",
       "  mean: 0.99254, std: 0.00372, params: {'max_depth': 9, 'min_child_weight': 5}],\n",
       " {'max_depth': 5, 'min_child_weight': 1},\n",
       " 0.9931343283582089)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "param = {\n",
    "    \"learning_rate\" :0.3,\n",
    "    \"n_estimators\":...,\n",
    "    \"max_depth\":7,\n",
    "    \"min_child_weight\":2,\n",
    "    'objective': 'multi:softprob',\n",
    "    'num_class': 3\n",
    "}\n",
    "\n",
    "param_test1 = {\n",
    " 'max_depth':...,\n",
    " 'min_child_weight':...\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier(param), param_grid = param_test1, cv=10)\n",
    "\n",
    "gsearch1.fit(X_train, y_train)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process can be repeated iteratively with the remaining parameters. A good heuristic is to follow this order next :\n",
    "Gamma, then (subsample and colsample_bytree) together, then reg_lambda and reg_alpha.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>Exercice 3 :</b> Complete the tuning and try to obtain the best performance of the model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# replace parameters for final evaluation\n",
    "param = {\n",
    "    \"learning_rate\" :0.1,\n",
    "    \"n_estimators\":76,\n",
    "    \"max_depth\":6,\n",
    "    \"min_child_weight\":1,\n",
    "    \"gamma\":0,\n",
    "    \"subsample\":0.8,\n",
    "    \"colsample_bytree\":0.8,\n",
    "    \"nthread\":4,\n",
    "    \"scale_pos_weight\":1,\n",
    "    'silent': 1,\n",
    "    'objective': 'multi:softprob',\n",
    "    'num_class': 3\n",
    "}\n",
    "\n",
    "\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "preds = bst.predict(dtest)\n",
    "predictions = np.asarray([np.argmax(line) for line in preds])\n",
    "print (precision_score(y_test, predictions, average='macro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion of the notebook\n",
    "\n",
    "In the notebook, we have seen the basic functions to use XGBoost. \n",
    "The next two notebooks will be more open-ended : the first one will be focused on the ensemble methods, while the second one will be focused on the tuning of the parameters, with regards to the tradeoff between biais and variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources : \n",
    "* https://www.kaggle.com/lucidlenn/data-analysis-and-classification-using-xgboost\n",
    "* https://github.com/dmlc/xgboost/tree/master/demo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
